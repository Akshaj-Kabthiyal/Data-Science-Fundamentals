{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd08d1c1",
   "metadata": {},
   "source": [
    "# Applying ML to sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019b71bf",
   "metadata": {},
   "source": [
    "## Preparing the IMDB Movie reviews dataset for sentiment analysis"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1294a896",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "basepath = 'aclImdb'\n",
    "\n",
    "labels = {'pos': 1, 'neg': 0}\n",
    "data = []\n",
    "\n",
    "# Estimate total files for progress bar (25,000 test + 25,000 train)\n",
    "total_files = 50000\n",
    "\n",
    "# Create a single tqdm progress bar\n",
    "with tqdm(total=total_files, desc='Reading IMDB reviews', unit='files') as pbar:\n",
    "    for s in ('test', 'train'):\n",
    "        for l in ('pos', 'neg'):\n",
    "            path = os.path.join(basepath, s, l)\n",
    "            for file in sorted(os.listdir(path)):\n",
    "                with open(os.path.join(path, file), 'r', encoding='utf-8') as infile:\n",
    "                    txt = infile.read()\n",
    "                data.append([txt, labels[l]])\n",
    "                pbar.update()\n",
    "\n",
    "df = pd.DataFrame(data, columns=['review', 'sentiment'])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efb7a0a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This film is an attempt to present Jared Diamo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Whereas the movie was beautifully shot and rea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The comparison is perhaps unfair, but inevitab...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It's hard and I didn't expect it... But it's r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elvira Mistress of the Dark is just that, a ca...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I own Ralph Bakshis forgotten masterpiece Fire...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Jason Bourne sits in a dusty room in with bloo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>Two college buddies - one an uptight nerd, the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>My school's drama club will be putting this sh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>\"Foxes\" is a great film. The four young actres...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "0      This film is an attempt to present Jared Diamo...          0\n",
       "1      Whereas the movie was beautifully shot and rea...          0\n",
       "2      The comparison is perhaps unfair, but inevitab...          0\n",
       "3      It's hard and I didn't expect it... But it's r...          0\n",
       "4      Elvira Mistress of the Dark is just that, a ca...          1\n",
       "...                                                  ...        ...\n",
       "49995  I own Ralph Bakshis forgotten masterpiece Fire...          1\n",
       "49996  Jason Bourne sits in a dusty room in with bloo...          1\n",
       "49997  Two college buddies - one an uptight nerd, the...          1\n",
       "49998  My school's drama club will be putting this sh...          1\n",
       "49999  \"Foxes\" is a great film. The four young actres...          1\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "df.to_csv('movie_data.csv', index=False)\n",
    "df = pd.read_csv('movie_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83e3b3a",
   "metadata": {},
   "source": [
    "## Bag of words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95adc6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'the': 6, 'sun': 4, 'is': 1, 'shining': 3, 'weather': 8, 'sweet': 5, 'and': 0, 'one': 2, 'two': 7}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count = CountVectorizer()\n",
    "docs = np.array(['The sun is shining',\n",
    "                 'The weather is sweet',\n",
    "                 'The sun is shining, the weather is sweet, and one and one is two'])\n",
    "bag = count.fit_transform(docs)\n",
    "print(count.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "849dcf0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 1 1 0 1 0 0]\n",
      " [0 1 0 0 0 1 1 0 1]\n",
      " [2 3 2 1 1 1 2 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(bag.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816f813d",
   "metadata": {},
   "source": [
    "## Assessing word relevancy via term frequency-inverse document  frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "841f940f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.43 0.   0.56 0.56 0.   0.43 0.   0.  ]\n",
      " [0.   0.43 0.   0.   0.   0.56 0.43 0.   0.56]\n",
      " [0.5  0.45 0.5  0.19 0.19 0.19 0.3  0.25 0.19]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf = TfidfTransformer(use_idf=True,\n",
    "                          norm='l2',\n",
    "                          smooth_idf=True)\n",
    "\n",
    "np.set_printoptions(precision=2)\n",
    "print(tfidf.fit_transform(count.fit_transform(docs)).toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ad270f",
   "metadata": {},
   "source": [
    "## Cleaning text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "574b8af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Saw it at the Philadelphia Gay and Lesbian Film Fest.<br /><br />What can I say? Against my better judgment, I liked it, but it seemed to me that that acting was a little...weak (mostly I noticed this from the family of the teen boy). I mean, the script wasn't stellar to begin with, but the actors didn't make me believe the relationships.<br /><br />The plot is also predictable.<br /><br />Nonethelss, I liked it. The characters are likable, and the plot is not challenging or upsetting. It's sweet, the characters care about each other, and I don't count it as fifty minutes ill-spent. <br /><br />But I don't recommend it.\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[10, 'review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "67c69fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocessor(text):\n",
    "    text = re.sub('<[^>]*>', '', text)\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)',text)\n",
    "    text = (re.sub('[\\W]+', ' ', text.lower()) +' '.join(emoticons).replace('-', ''))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7331b356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'saw it at the philadelphia gay and lesbian film fest what can i say against my better judgment i liked it but it seemed to me that that acting was a little weak mostly i noticed this from the family of the teen boy i mean the script wasn t stellar to begin with but the actors didn t make me believe the relationships the plot is also predictable nonethelss i liked it the characters are likable and the plot is not challenging or upsetting it s sweet the characters care about each other and i don t count it as fifty minutes ill spent but i don t recommend it '"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor(df.loc[10, 'review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "927d7ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a test :) :( :)'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor(\"</a>This :) is :( a test :-)!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bf872414",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review'] = df['review'].apply(preprocessor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83222be",
   "metadata": {},
   "source": [
    "## Processing documents into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bf792488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['runners', 'like', 'running', 'and', 'thus', 'they', 'run']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenizer(text):\n",
    "    return text.split()\n",
    "tokenizer('runners like running and thus they run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df009264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['runner', 'like', 'run', 'and', 'thu', 'they', 'run']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "def tokenizer_porter(text):\n",
    "    return [porter.stem(word) for word in text.split()]\n",
    "tokenizer_porter('runners like running and thus they run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "378b5b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Aksha\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['runner', 'like', 'run', 'run', 'lot']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "[w for w in tokenizer_porter('a runner likes running and runs a lot') if w not in stop]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5827fee3",
   "metadata": {},
   "source": [
    "## Training a logistic regression model for document classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a5c3e081",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.loc[:25000, 'review'].values\n",
    "y_train = df.loc[:25000, 'sentiment'].values\n",
    "X_test = df.loc[25000:, 'review'].values\n",
    "y_test = df.loc[25000:, 'sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762f6ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(strip_accents=None,\n",
    "                        lowercase=False,\n",
    "                        preprocessor=None)\n",
    "small_param_grid = [\n",
    "    {\n",
    "         'vect__ngram_range': [(1, 1)],\n",
    "         'vect__stop_words': [None],\n",
    "         'vect__tokenizer': [tokenizer, tokenizer_porter],\n",
    "         'clf__penalty': ['l2'],\n",
    "         'clf__C': [1.0, 10.0]\n",
    "     },\n",
    "    {\n",
    "        'vect__ngram_range': [(1, 1)],\n",
    "        'vect__stop_words': [stop, None],\n",
    "        'vect__tokenizer': [tokenizer],\n",
    "        'vect__use_idf':[False],\n",
    "        'vect__norm':[None],\n",
    "        'clf__penalty': ['l2'],\n",
    "        'clf__C': [1.0, 10.0]\n",
    "    },\n",
    " ]\n",
    "lr_tfidf = Pipeline([\n",
    "                        ('vect', tfidf),\n",
    "                        ('clf', LogisticRegression(solver='liblinear'))\n",
    "                    ])\n",
    "gs_lr_tfidf = GridSearchCV(lr_tfidf, small_param_grid,\n",
    "                           scoring='accuracy', cv=5,\n",
    "                           verbose=2, n_jobs=5)\n",
    "gs_lr_tfidf.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
